{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Neuromorphic Software: Phase-Encoding\n",
    "\n",
    "What it is\n",
    "What it does\n",
    "Explain fixed bio encoder + learnable MultiLayerPerceptron for Readout (classifier)\n"
   ],
   "id": "16bb457ff771456f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Phase Encoding - The Maths\n",
    "Here's a LaTeX representation of the mathematical function implemented in `encode_image()`:\n",
    "\n",
    "## Input:\n",
    "\n",
    "- $I$: Flattened image (a vector of pixel values)\n",
    "- $\\omega_{active}$: Active frequency parameter\n",
    "- $x$: Spatial layout parameter (a vector)\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- $\\theta_{thresh}$: Threshold phase (set to 0.0 in the code). When a Neuron's phase has rotated through $2\\pi$ to $0$ we consider the Neuron has generated a Spike.\n",
    "- $\\omega_{ref}$: Reference frequency\n",
    "- $n$ A constant (set to 4.0 in the code)\n",
    "- $\\kappa$: A constant (set to $2\\pi$ in the code)\n",
    "\n",
    "## Calculations:\n",
    "\n",
    "#### Initial Phase: $$\\theta_{init} = I \\cdot 2\\pi$$\n",
    "\n",
    "#### Phase Difference: $$\\Delta\\theta = (\\theta_{thresh} - \\theta_{init} + 2\\pi) \\pmod{2\\pi}$$\n",
    "\n",
    "#### Spike Time: $$t_{spike} = \\frac{\\Delta\\theta}{\\omega_{active}}$$\n",
    "\n",
    "#### Reference Phase: $$\\theta_{ref} = \\left(\\frac{\\omega_{ref} \\cdot t_{spike} + \\kappa \\cdot x}{n}\\right) \\pmod{2\\pi}$$\n",
    "\n",
    "#### Final Phase Difference: $$\\phi = (\\theta_{thresh} - \\theta_{ref} + 2\\pi) \\pmod{2\\pi}$$\n",
    "\n",
    "## Output:\n",
    "\n",
    "- Encoded image: $[\\cos(\\phi), \\sin(\\phi)]$ (a concatenated vector of cosine and sine of the final phase difference)\n",
    "\n",
    "### Formal Definition:\n",
    "\n",
    "$$ \\text{encode\\_image}(I, \\omega_{active}, x) = [\\cos(\\phi), \\sin(\\phi)] $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\phi = (\\theta_{thresh} - \\theta_{ref} + 2\\pi) \\pmod{2\\pi} $$\n",
    "\n",
    "and $\\theta_{ref}$ is calculated as described in the steps above.\n",
    "\n",
    "This definition encapsulates the mathematical operations performed by the `encode_image()` function, providing a concise and formal representation of the phase encoding process.\n"
   ],
   "id": "d127c44cfcba7cd8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T11:17:15.052368Z",
     "start_time": "2025-04-23T11:00:06.759494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Device Configuration ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 1. Load and Normalize MNIST ---\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomRotation(35),  # Rotate images by up to 25 degrees\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Translate by up to 10%\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Mean and std deviation for MNIST\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Mean and std deviation for MNIST\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# --- Split training data into training and validation sets ---\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# --- 2. Dataloaders ---\n",
    "batch_size = 100  # Increase batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# --- 3. Phase Encoding Parameters ---\n",
    "N = 28 * 28\n",
    "omega_active = torch.ones(N, dtype=torch.float32) * 2 * np.pi * 20.0\n",
    "theta_thresh = 0.0\n",
    "omega_ref = 2 * np.pi * 8.0\n",
    "n = 4.0\n",
    "kappa = 2 * np.pi\n",
    "x = torch.linspace(0, 1, N, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# --- 4. Phase Encoder Function ---\n",
    "def encode_image(img_flat, omega_active_param, x_param):\n",
    "    theta_init = (img_flat * 2 * np.pi)\n",
    "    delta_theta = torch.fmod(theta_thresh - theta_init + 2 * np.pi, 2 * np.pi)\n",
    "    t_spike = delta_theta / omega_active_param\n",
    "    theta_ref = torch.fmod((omega_ref * t_spike + kappa * x_param) / n, 2 * np.pi)\n",
    "    phase_diff = torch.fmod(theta_thresh - theta_ref + 2 * np.pi, 2 * np.pi)\n",
    "    return torch.cat([torch.cos(phase_diff), torch.sin(phase_diff)])\n",
    "\n",
    "\n",
    "# --- 5. Define Classifier ---\n",
    "class PhaseClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(PhaseClassifier, self).__init__()\n",
    "        self.layer1 = nn.Linear(N * 2, 784)\n",
    "        self.layer2 = nn.Linear(784, 512)\n",
    "        self.layer3 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)  # Add dropout layer\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, omega_active, spatial_layout):\n",
    "        encoded_images = []\n",
    "        for img in x:\n",
    "            img_flat = img.view(-1)  # Flatten the image\n",
    "            encoded_img = encode_image(img_flat, omega_active, spatial_layout)\n",
    "            encoded_images.append(encoded_img)\n",
    "        encoded_images = torch.stack(encoded_images)\n",
    "        encoded_images = self.dropout(encoded_images)  # Apply dropout\n",
    "        x = self.relu(self.layer1(encoded_images))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        logits = self.layer3(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# --- 6. Training Loop ---\n",
    "num_classes = 10\n",
    "model = PhaseClassifier(num_classes).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- Early Stopping Parameters ---\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "counter = 0\n",
    "\n",
    "num_epochs = 30  # Train for more epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", leave=False)\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images, omega_active.to(device), x.to(device))\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update tqdm loop\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images, omega_active.to(device), x.to(device))\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # --- Early Stopping ---\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "# --- 7. Evaluation ---\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images, omega_active.to(device), x.to(device))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the test set: {accuracy:.2f}%\")"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:06<00:00, 1608207.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 257774.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:02<00:00, 703103.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 2265223.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:   0%|          | 0/480 [00:00<?, ?it/s]/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: Skipping device NVIDIA GeForce GT 750M that does not support Metal 2.0 (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1711403213615/work/aten/src/ATen/mps/MPSDevice.mm:101.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 1.4843, Validation Loss: 1.4621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Loss: 1.2792, Validation Loss: 1.3284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Loss: 1.0391, Validation Loss: 1.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Loss: 0.9410, Validation Loss: 0.9420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Loss: 0.9094, Validation Loss: 0.8504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Loss: 0.7878, Validation Loss: 0.7932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Loss: 0.8226, Validation Loss: 0.7014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Loss: 0.7445, Validation Loss: 0.6780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Loss: 0.6991, Validation Loss: 0.6404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Loss: 0.7464, Validation Loss: 0.6339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Loss: 0.5971, Validation Loss: 0.5584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Loss: 0.5966, Validation Loss: 0.5421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Loss: 0.7167, Validation Loss: 0.5464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Loss: 0.6808, Validation Loss: 0.5079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Loss: 0.6042, Validation Loss: 0.4925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Loss: 0.6795, Validation Loss: 0.5230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Loss: 0.5036, Validation Loss: 0.4747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Loss: 0.6183, Validation Loss: 0.5004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Loss: 0.4274, Validation Loss: 0.4272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Loss: 0.5509, Validation Loss: 0.4650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Loss: 0.6002, Validation Loss: 0.4874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Loss: 0.5609, Validation Loss: 0.4358\n",
      "Early stopping triggered!\n",
      "Accuracy on the test set: 92.10%\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Ablation Study:\n",
    "\n",
    "We'll create a modified version of the code where we remove the `t_spike` calculation and directly encode the pixel values using cosine and sine.\n",
    "\n",
    "Comparing the performance of this modified version to our original model should further evidence the importance of the first spike time calculation."
   ],
   "id": "c65915d81540a464"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def direct_encode(img_flat, encoding_dim):\n",
    "    \"\"\"\n",
    "    Directly encodes pixel values using cosine and sine functions.\n",
    "\n",
    "    Args:\n",
    "      img_flat: A flattened PyTorch tensor representing the image pixels.\n",
    "      encoding_dim: The dimensionality of the encoding.\n",
    "\n",
    "    Returns:\n",
    "      A PyTorch tensor containing the encoded representation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a range of values for the encoding dimensions\n",
    "    encoding_indices = torch.arange(encoding_dim, dtype=torch.float32, device=img_flat.device)\n",
    "\n",
    "    # Scale pixel values to the range [0, 2*pi]\n",
    "    scaled_pixels = img_flat * 2 * torch.pi\n",
    "\n",
    "    # Calculate cosine and sine encodings\n",
    "    cos_encoding = torch.cos(scaled_pixels[:, None] * encoding_indices[None, :])\n",
    "    sin_encoding = torch.sin(scaled_pixels[:, None] * encoding_indices[None, :])\n",
    "\n",
    "    # Concatenate cosine and sine encodings\n",
    "    encoded_representation = torch.cat([cos_encoding, sin_encoding], dim=-1)\n",
    "\n",
    "    return encoded_representation"
   ],
   "id": "7934e8f787b3768a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
