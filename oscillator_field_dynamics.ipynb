{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Oscillator Field Dynamics\n",
   "id": "e8f6a1834f7995"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Notebook setup\n",
    "\n",
    "Imports, Random Seeding, Device Setup - Training time varies based on hardware: approximately 20 minutes on CPU, and significantly faster on GPU.\n"
   ],
   "id": "42d518d13fdd02cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:47:18.861061Z",
     "start_time": "2025-04-23T18:47:18.851590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from IPython import display\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# to ensure reproducibility, we should set the random seed consistently\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)  # for multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# mathematical constants\n",
    "EPSILON: float = 1e-12 # for safe division\n",
    "TWO_PI: 2 * np.pi"
   ],
   "id": "82bab875e7d6c6d8",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Device Setup\n",
    "Will output `Using device: cuda` if running on GPU.\n",
    "If `Using device: cpu` will take significantly longer."
   ],
   "id": "1a3f6af3449e6420"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:47:18.909267Z",
     "start_time": "2025-04-23T18:47:18.905108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Device Configuration ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ],
   "id": "caa6ebf46d331b03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Experiment Setup\n",
    "Description goes here..\n"
   ],
   "id": "6213ca96b7a5022e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:47:18.962053Z",
     "start_time": "2025-04-23T18:47:18.955848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 0.0 Define Experiment Parameters ---\n",
    "NUM_CLASSES = 10  # 10 digits in MNIST Dataset\n",
    "MAX_ROTATION_DEGREES = 35  # Rotate images by up to 35 degrees\n",
    "MAX_TRANSLATION = 0.1  # Translate images by up to 10%\n",
    "\n",
    "# --- 0.1 Define Oscillator Field Parameters ---\n",
    "TIMESTEPS = 2048\n",
    "\n",
    "# --- 0.2 Define Training Parameters ---\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "PATIENCE = 3\n"
   ],
   "id": "b6c87b8890b8c23a",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading and Preprocessing MNIST Data\n",
    "- Defines image transformations to be applied to the training and testing data, respectively.\n",
    "- The training data is augmented with random rotations and translations.\n",
    "- Both datasets are converted to PyTorch tensors and normalized.\n",
    "- Normalization is crucial as it helps neural networks converge faster and perform better by ensuring all input features are on a similar scale and centered around zero.\n",
    "- Loads the MNIST dataset.\n",
    "- The root argument specifies where to store the data, train=True indicates the training set, and download=True downloads the data if it's not already present.\n",
    "- Splits the training data into training and validation sets.\n",
    "- This is important to evaluate the model's performance during training and prevent overfitting.\n",
    "- Creates data loaders for the training, validation, and testing sets.\n",
    "- These loaders handle batching and shuffling of the data, making it easier to feed into the model during training and evaluation.\n"
   ],
   "id": "eb836d10c6285a2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:47:19.307805Z",
     "start_time": "2025-04-23T18:47:19.211454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Mean and std deviation for MNIST\n",
    "MNIST_MEAN = 0.1307\n",
    "MNIST_STD = 0.3081\n",
    "transform_normalize_to_mnist_mean_and_std = transforms.Normalize((MNIST_MEAN,), (MNIST_STD,))\n",
    "\n",
    "# --- 1. Load and Normalize MNIST ---\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomRotation(MAX_ROTATION_DEGREES),\n",
    "    transforms.RandomAffine(degrees=0, translate=(MAX_TRANSLATION, MAX_TRANSLATION)),\n",
    "    transforms.ToTensor(),\n",
    "    transform_normalize_to_mnist_mean_and_std\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transform_normalize_to_mnist_mean_and_std\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# --- Split training data into training and validation sets ---\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# --- 2. Dataloaders ---\n",
    "batch_size = BATCH_SIZE\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "110d05b1a8c28bda",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## MNIST DEMO\n",
    "For now, this grabs a single digit from the MNIST dataset to demonstrate the field dynamics."
   ],
   "id": "2e843f47d4dddbb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:47:19.932280Z",
     "start_time": "2025-04-23T18:47:19.844260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load MNIST digit\n",
    "DIGIT = 6  # Using integer instead of string for PyTorch\n",
    "INVERT_POLARITY = True\n",
    "H, W, D = 28, 28, 4  # Original MNIST dimensions\n",
    "\n",
    "# Load single digit from MNIST \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transform_normalize_to_mnist_mean_and_std\n",
    "])\n",
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "digit_idx = next(idx for idx, (_, label) in enumerate(dataset) if label == DIGIT)\n",
    "the_digit = dataset[digit_idx][0].squeeze().numpy()  # Get first instance of digit 6\n",
    "\n",
    "# Scale to 0-2π and invert polarity\n",
    "the_digit = (the_digit * 2 * np.pi)  # Scale 0-1 to 0-2π\n",
    "the_digit = 2 * np.pi - the_digit if INVERT_POLARITY else the_digit\n",
    "\n",
    "# Create perturbation (28x28x4) as numpy array\n",
    "perturbation = np.zeros((H, W, D), dtype=np.float32)\n",
    "perturbation[:, :, 0] = the_digit\n",
    "for d in range(1, D): # copy the perturbation across all dimensions\n",
    "    perturbation[:, :, d] = perturbation[:, :, 0]"
   ],
   "id": "af5ad960f96287",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Kuramoto Oscillator Model\n",
    "Description goes here.."
   ],
   "id": "851a6d8733bee227"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:52:16.652236Z",
     "start_time": "2025-04-23T18:52:16.635723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class KuramotoVectorOscillatorField:\n",
    "    def __init__(\n",
    "        self,\n",
    "        height: int,\n",
    "        width: int,\n",
    "        dims: int = 4,\n",
    "        delta_t: float = 0.01,\n",
    "        k_coupling: float = 0.5,\n",
    "        k_omega: float = 1.0,\n",
    "        k_bias: float = 0.3,\n",
    "        spike_thresh: float = 0.01,\n",
    "        initial_phases: torch.Tensor | None = None,\n",
    "        device: torch.device = torch.device(\"cpu\"),\n",
    "    ) -> None:\n",
    "        self.H, self.W, self.D = height, width, dims\n",
    "        self.delta_t = delta_t\n",
    "        self.k_coupling = k_coupling\n",
    "        self.k_omega = k_omega\n",
    "        self.k_bias = k_bias\n",
    "        self.spike_thresh = spike_thresh\n",
    "        self.device = device\n",
    "\n",
    "        # Initialize phases if not provided and move to the specified device.\n",
    "        if initial_phases is None:\n",
    "            initial_phases = torch.rand(self.H, self.W, self.D, device=self.device) * 2 * math.pi\n",
    "\n",
    "        # Oscillator state: unit complex vectors (H, W, D)\n",
    "        # PyTorch supports complex tensors as of version 1.6.\n",
    "        self.z = torch.exp(1j * initial_phases)\n",
    "        self.z_prev = self.z.clone()\n",
    "\n",
    "        # External bias (input) - initialised to initial phase field\n",
    "        self.c = self.z.clone()\n",
    "\n",
    "        # Skew-symmetric omega for cross-dimensional coupling (D, D)\n",
    "        # Create a random matrix and subtract its transpose.\n",
    "        omega = torch.randn(self.D, self.D, device=self.device)\n",
    "        self.omega = omega - omega.T\n",
    "\n",
    "    def neighbor_sum(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        # Add a padding of 1 along each dimension.\n",
    "        # For 3D tensor, pad order for F.pad is (last dim start, last dim end, second last dim start, second last dim end, first dim start, first dim end)\n",
    "        z_padded = F.pad(z, (1, 1, 1, 1, 1, 1), mode=\"constant\", value=0)\n",
    "\n",
    "        # Six-neighbor summation\n",
    "        # Note that z has shape (H, W, D) and we sum neighbors along each axis.\n",
    "        neighbors = (\n",
    "            z_padded[1:-1, 1:-1, :-2] +    # Negative direction along D\n",
    "            z_padded[1:-1, 1:-1, 2:] +     # Positive direction along D\n",
    "            z_padded[1:-1, :-2, 1:-1] +    # Negative direction along W\n",
    "            z_padded[1:-1, 2:, 1:-1] +     # Positive direction along W\n",
    "            z_padded[:-2, 1:-1, 1:-1] +    # Negative direction along H\n",
    "            z_padded[2:, 1:-1, 1:-1]       # Positive direction along H\n",
    "        )\n",
    "        return neighbors\n",
    "\n",
    "    def normalize(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        # Normalize each complex number to have unit magnitude\n",
    "        return z / (torch.abs(z) + EPSILON)\n",
    "\n",
    "    def step(self, evolve_c: bool = False) -> torch.Tensor:\n",
    "        self.z_prev = self.z.clone()\n",
    "\n",
    "        # 1. Local spatial coupling\n",
    "        z_neighbors = self.neighbor_sum(self.z)\n",
    "\n",
    "        # 2. Cross-dimensional omega interaction\n",
    "        # Using torch.einsum, note that self.z is of shape (H, W, D)\n",
    "        z_omega = torch.einsum(\"ij,hwj->hwi\", self.omega, self.z)\n",
    "\n",
    "        # 3. Input bias direction\n",
    "        bias = self.c - self.z\n",
    "\n",
    "        # 4. Total update\n",
    "        delta_z = (\n",
    "            self.k_coupling * (z_neighbors - self.z)\n",
    "            + self.k_omega * z_omega\n",
    "            + self.k_bias * bias\n",
    "        )\n",
    "\n",
    "        # 5. Euler update + normalize\n",
    "        self.z = self.normalize(self.z + self.delta_t * delta_z)\n",
    "\n",
    "        # 6. Compute spikes (phase velocity)\n",
    "        # Compute the phase difference between current and previous steps.\n",
    "        # torch.angle returns the phase of a complex tensor.\n",
    "        delta_theta = torch.angle(self.z * torch.conj(self.z_prev))\n",
    "        spike_activity = (torch.abs(delta_theta) > self.spike_thresh).float()\n",
    "\n",
    "        # 7. Evolve external input field if requested\n",
    "        if evolve_c:\n",
    "            delta_c = 0.1 * (self.z - self.c)\n",
    "            self.c = self.normalize(self.c + self.delta_t * delta_c)\n",
    "\n",
    "        return spike_activity\n",
    "\n",
    "    def run(\n",
    "        self, steps: int = 100, evolve_c: bool = False, return_history: bool = False\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor] | tuple[list[torch.Tensor], list[torch.Tensor]]:\n",
    "        z_history_list = []\n",
    "        spike_history_list = []\n",
    "        spikes_generated = torch.zeros((self.H, self.W, self.D), device=self.device)\n",
    "        for _ in range(steps):\n",
    "            spikes_generated = self.step(evolve_c=evolve_c)\n",
    "            if return_history:\n",
    "                z_history_list.append(self.z.clone())\n",
    "                spike_history_list.append(spikes_generated.clone())\n",
    "        if return_history:\n",
    "            return z_history_list, spike_history_list\n",
    "        else:\n",
    "            return self.z, spikes_generated"
   ],
   "id": "2d3164869a6e8f82",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run the Physics Simulation",
   "id": "7da242071f583604"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T18:52:31.177699Z",
     "start_time": "2025-04-23T18:52:31.049320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize field\n",
    "field = KuramotoVectorOscillatorField(\n",
    "    height=H,\n",
    "    width=W,\n",
    "    dims=D,\n",
    "    delta_t=0.01,\n",
    "    k_coupling=0.12,\n",
    "    k_omega=0.12,\n",
    "    k_bias=1.25,\n",
    "    spike_thresh=0.00035,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# Introduce perturbation as a symmetry-breaking condition\n",
    "field.c = torch.exp(1j * torch.from_numpy(perturbation).to(DEVICE))\n",
    "\n",
    "# Run for (default:2048) steps\n",
    "z_history, spike_history = field.run(steps=TIMESTEPS, evolve_c=True, return_history=True)"
   ],
   "id": "c9aea1266f8f14a",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type ComplexFloat but found Float",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[42]\u001B[39m\u001B[32m, line 18\u001B[39m\n\u001B[32m     15\u001B[39m field.c = torch.exp(\u001B[32m1\u001B[39mj * torch.from_numpy(perturbation).to(DEVICE))\n\u001B[32m     17\u001B[39m \u001B[38;5;66;03m# Run for (default:2048) steps\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m z_history, spike_history = \u001B[43mfield\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43msteps\u001B[49m\u001B[43m=\u001B[49m\u001B[43mTIMESTEPS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevolve_c\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_history\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[40]\u001B[39m\u001B[32m, line 108\u001B[39m, in \u001B[36mKuramotoVectorOscillatorField.run\u001B[39m\u001B[34m(self, steps, evolve_c, return_history)\u001B[39m\n\u001B[32m    106\u001B[39m spikes_generated = torch.zeros((\u001B[38;5;28mself\u001B[39m.H, \u001B[38;5;28mself\u001B[39m.W, \u001B[38;5;28mself\u001B[39m.D), device=\u001B[38;5;28mself\u001B[39m.device)\n\u001B[32m    107\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(steps):\n\u001B[32m--> \u001B[39m\u001B[32m108\u001B[39m     spikes_generated = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevolve_c\u001B[49m\u001B[43m=\u001B[49m\u001B[43mevolve_c\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    109\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m return_history:\n\u001B[32m    110\u001B[39m         z_history_list.append(\u001B[38;5;28mself\u001B[39m.z.clone())\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[40]\u001B[39m\u001B[32m, line 73\u001B[39m, in \u001B[36mKuramotoVectorOscillatorField.step\u001B[39m\u001B[34m(self, evolve_c)\u001B[39m\n\u001B[32m     69\u001B[39m z_neighbors = \u001B[38;5;28mself\u001B[39m.neighbor_sum(\u001B[38;5;28mself\u001B[39m.z)\n\u001B[32m     71\u001B[39m \u001B[38;5;66;03m# 2. Cross-dimensional omega interaction\u001B[39;00m\n\u001B[32m     72\u001B[39m \u001B[38;5;66;03m# Using torch.einsum, note that self.z is of shape (H, W, D)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m73\u001B[39m z_omega = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43meinsum\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mij,hwj->hwi\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43momega\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mz\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     75\u001B[39m \u001B[38;5;66;03m# 3. Input bias direction\u001B[39;00m\n\u001B[32m     76\u001B[39m bias = \u001B[38;5;28mself\u001B[39m.c - \u001B[38;5;28mself\u001B[39m.z\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/torch/functional.py:380\u001B[39m, in \u001B[36meinsum\u001B[39m\u001B[34m(*args)\u001B[39m\n\u001B[32m    375\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m einsum(equation, *_operands)\n\u001B[32m    377\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(operands) <= \u001B[32m2\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m opt_einsum.enabled:\n\u001B[32m    378\u001B[39m     \u001B[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001B[39;00m\n\u001B[32m    379\u001B[39m     \u001B[38;5;66;03m# or the user has disabled using opt_einsum\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m380\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_VF\u001B[49m\u001B[43m.\u001B[49m\u001B[43meinsum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mequation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperands\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[32m    382\u001B[39m path = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    383\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m opt_einsum.is_available():\n",
      "\u001B[31mRuntimeError\u001B[39m: expected scalar type ComplexFloat but found Float"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualise",
   "id": "e5826849ff542990"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def generate_phase_plot(Z, labels, title=\"Phase Space Trajectory\", use_tsne=False):\n",
    "    \"\"\"\n",
    "    Z: np.ndarray of shape [T, N, D] where\n",
    "       T = timesteps or layers,\n",
    "       N = number of samples,\n",
    "       D = phase-feature dimension (e.g. 2*neurons)\n",
    "\n",
    "    labels: np.ndarray of shape [N] — class labels per sample\n",
    "    \"\"\"\n",
    "    T, N, D = Z.shape\n",
    "    all_points = []\n",
    "\n",
    "    for t in range(T):\n",
    "        if use_tsne:\n",
    "            from sklearn.manifold import TSNE\n",
    "            reducer = TSNE(n_components=2, perplexity=30, init='pca', random_state=42)\n",
    "        else:\n",
    "            reducer = PCA(n_components=2)\n",
    "\n",
    "        points_2d = reducer.fit_transform(Z[t])\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"x\": points_2d[:, 0],\n",
    "            \"y\": points_2d[:, 1],\n",
    "            \"class\": labels.astype(str),\n",
    "            \"timestep\": t\n",
    "        })\n",
    "        all_points.append(df)\n",
    "\n",
    "    df_all = pd.concat(all_points)\n",
    "\n",
    "    fig = px.scatter(df_all, x=\"x\", y=\"y\", color=\"class\",\n",
    "                     animation_frame=\"timestep\",\n",
    "                     title=title,\n",
    "                     labels={\"class\": \"Digit Class\"},\n",
    "                     opacity=0.7,\n",
    "                     width=900, height=700)\n",
    "\n",
    "    fig.update_traces(marker=dict(size=6), selector=dict(mode='markers'))\n",
    "    fig.update_layout(template=\"plotly_dark\", transition_duration=300)\n",
    "    fig.show()\n"
   ],
   "id": "e75af35a4d0d6c59",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
